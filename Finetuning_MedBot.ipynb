{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15a4580977094acbb1ff12a6531c6305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3b4cda931d441479827864f4e310e48",
              "IPY_MODEL_0ab6a432f7f54e4a9df0c0e4ae26459c",
              "IPY_MODEL_b151383ebf41464883366f9f9004b012"
            ],
            "layout": "IPY_MODEL_d72a7540ae984ffca8219b3b585c7d4b"
          }
        },
        "d3b4cda931d441479827864f4e310e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d64055eec62046f39dd5da6a72b37e30",
            "placeholder": "​",
            "style": "IPY_MODEL_53fedb6c1da74c85b990af3d288b7a70",
            "value": "Map: 100%"
          }
        },
        "0ab6a432f7f54e4a9df0c0e4ae26459c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7565e181005456d8842935f016a3cc5",
            "max": 25371,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_882952c24407485ea91cc8b8cabd143c",
            "value": 25371
          }
        },
        "b151383ebf41464883366f9f9004b012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f7305adf8304d8384cd3f75b2323cca",
            "placeholder": "​",
            "style": "IPY_MODEL_a4dda6a5ef614d6eac3dd27052b5b6c7",
            "value": " 25371/25371 [00:50&lt;00:00, 586.50 examples/s]"
          }
        },
        "d72a7540ae984ffca8219b3b585c7d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64055eec62046f39dd5da6a72b37e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53fedb6c1da74c85b990af3d288b7a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7565e181005456d8842935f016a3cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "882952c24407485ea91cc8b8cabd143c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f7305adf8304d8384cd3f75b2323cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4dda6a5ef614d6eac3dd27052b5b6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanaImran0/fine-tuning/blob/main/Finetuning_MedBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexLcIy80J74",
        "outputId": "75d22a59-7a62-4fea-d967-38d44c1e0825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyKkQWGJ0hLh",
        "outputId": "dfa252df-f9ca-4fe9-d9aa-02a2eb2e7c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELoxl3aewuM8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import os\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.checkpoint\n",
        "torch.utils.checkpoint.checkpoint = lambda function, *args, **kwargs: function(*args, **kwargs)"
      ],
      "metadata": {
        "id": "wJfu44GtInq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"stanford-crfm/BioMedLM\"\n",
        "dataset_name = \"FreedomIntelligence/medical-o1-reasoning-SFT\"\n",
        "output_dir = \"./medical-o1-reasoning-SFT\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "pV4IdKfP0PuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")"
      ],
      "metadata": {
        "id": "_W1BL6ZQ0Uuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDoaqn6Y0V-V",
        "outputId": "4050cb30-b6ae-473b-8ad6-4f81b692e3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "ASVFB9qd0VsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, 'en')\n",
        "print(f\"Dataset structure: {dataset}\")\n",
        "print(f\"Dataset columns: {dataset['train'].column_names}\")\n",
        "print(f\"Sample data: {dataset['train'][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0ruXkV20VfT",
        "outputId": "8b83d588-9a68-4ffe-f608-42b502f0f785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset structure: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Question', 'Complex_CoT', 'Response'],\n",
            "        num_rows: 25371\n",
            "    })\n",
            "})\n",
            "Dataset columns: ['Question', 'Complex_CoT', 'Response']\n",
            "Sample data: {'Question': 'A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?', 'Complex_CoT': \"Okay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem. \\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal. \\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\", 'Response': 'Cystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    formatted_inputs = []\n",
        "    for question, cot, response in zip(examples[\"Question\"], examples[\"Complex_CoT\"], examples[\"Response\"]):\n",
        "        formatted_text = f\"Question: {question}\\nReasoning: {cot}\\nAnswer: {response}\"\n",
        "        formatted_inputs.append(formatted_text)\n",
        "\n",
        "    tokenized = tokenizer(\n",
        "        formatted_inputs,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
        "\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "i5vQa0Kj1hQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"Question\", \"Complex_CoT\", \"Response\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "15a4580977094acbb1ff12a6531c6305",
            "d3b4cda931d441479827864f4e310e48",
            "0ab6a432f7f54e4a9df0c0e4ae26459c",
            "b151383ebf41464883366f9f9004b012",
            "d72a7540ae984ffca8219b3b585c7d4b",
            "d64055eec62046f39dd5da6a72b37e30",
            "53fedb6c1da74c85b990af3d288b7a70",
            "b7565e181005456d8842935f016a3cc5",
            "882952c24407485ea91cc8b8cabd143c",
            "7f7305adf8304d8384cd3f75b2323cca",
            "a4dda6a5ef614d6eac3dd27052b5b6c7"
          ]
        },
        "id": "o7xf1E1Q1hKz",
        "outputId": "055da5cb-6a6b-455e-cd7f-1de8d9f0ec4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25371 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15a4580977094acbb1ff12a6531c6305"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "-fsnCI0T1hDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_modules(model):\n",
        "    modules = []\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            modules.append(name)\n",
        "\n",
        "    print(\"Potential LoRA target modules:\")\n",
        "    for module in modules:\n",
        "        print(f\"  - {module}\")\n",
        "\n",
        "    patterns = [\"query\", \"key\", \"value\", \"attention\", \"mlp\", \"dense\"]\n",
        "    print(\"\\nModules containing common patterns:\")\n",
        "    for pattern in patterns:\n",
        "        matching = [m for m in [] if pattern in m.lower()]\n",
        "        if matching:\n",
        "            print(f\"Pattern '{pattern}':\")\n",
        "            for m in matching[:5]:\n",
        "                print(f\"  - {m}\")\n",
        "            if len(matching) > 5:\n",
        "                print(f\"  ... and {len(matching) - 5} more\")\n",
        "    return modules\n",
        "\n",
        "trainable_modules = print_trainable_modules(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWMNGFlc12bh",
        "outputId": "2acd26ca-c167-4585-89ba-556e0f73fd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Potential LoRA target modules:\n",
            "  - transformer.h.0.attn.c_attn\n",
            "  - transformer.h.0.attn.c_proj\n",
            "  - transformer.h.0.mlp.c_fc\n",
            "  - transformer.h.0.mlp.c_proj\n",
            "  - transformer.h.1.attn.c_attn\n",
            "  - transformer.h.1.attn.c_proj\n",
            "  - transformer.h.1.mlp.c_fc\n",
            "  - transformer.h.1.mlp.c_proj\n",
            "  - transformer.h.2.attn.c_attn\n",
            "  - transformer.h.2.attn.c_proj\n",
            "  - transformer.h.2.mlp.c_fc\n",
            "  - transformer.h.2.mlp.c_proj\n",
            "  - transformer.h.3.attn.c_attn\n",
            "  - transformer.h.3.attn.c_proj\n",
            "  - transformer.h.3.mlp.c_fc\n",
            "  - transformer.h.3.mlp.c_proj\n",
            "  - transformer.h.4.attn.c_attn\n",
            "  - transformer.h.4.attn.c_proj\n",
            "  - transformer.h.4.mlp.c_fc\n",
            "  - transformer.h.4.mlp.c_proj\n",
            "  - transformer.h.5.attn.c_attn\n",
            "  - transformer.h.5.attn.c_proj\n",
            "  - transformer.h.5.mlp.c_fc\n",
            "  - transformer.h.5.mlp.c_proj\n",
            "  - transformer.h.6.attn.c_attn\n",
            "  - transformer.h.6.attn.c_proj\n",
            "  - transformer.h.6.mlp.c_fc\n",
            "  - transformer.h.6.mlp.c_proj\n",
            "  - transformer.h.7.attn.c_attn\n",
            "  - transformer.h.7.attn.c_proj\n",
            "  - transformer.h.7.mlp.c_fc\n",
            "  - transformer.h.7.mlp.c_proj\n",
            "  - transformer.h.8.attn.c_attn\n",
            "  - transformer.h.8.attn.c_proj\n",
            "  - transformer.h.8.mlp.c_fc\n",
            "  - transformer.h.8.mlp.c_proj\n",
            "  - transformer.h.9.attn.c_attn\n",
            "  - transformer.h.9.attn.c_proj\n",
            "  - transformer.h.9.mlp.c_fc\n",
            "  - transformer.h.9.mlp.c_proj\n",
            "  - transformer.h.10.attn.c_attn\n",
            "  - transformer.h.10.attn.c_proj\n",
            "  - transformer.h.10.mlp.c_fc\n",
            "  - transformer.h.10.mlp.c_proj\n",
            "  - transformer.h.11.attn.c_attn\n",
            "  - transformer.h.11.attn.c_proj\n",
            "  - transformer.h.11.mlp.c_fc\n",
            "  - transformer.h.11.mlp.c_proj\n",
            "  - transformer.h.12.attn.c_attn\n",
            "  - transformer.h.12.attn.c_proj\n",
            "  - transformer.h.12.mlp.c_fc\n",
            "  - transformer.h.12.mlp.c_proj\n",
            "  - transformer.h.13.attn.c_attn\n",
            "  - transformer.h.13.attn.c_proj\n",
            "  - transformer.h.13.mlp.c_fc\n",
            "  - transformer.h.13.mlp.c_proj\n",
            "  - transformer.h.14.attn.c_attn\n",
            "  - transformer.h.14.attn.c_proj\n",
            "  - transformer.h.14.mlp.c_fc\n",
            "  - transformer.h.14.mlp.c_proj\n",
            "  - transformer.h.15.attn.c_attn\n",
            "  - transformer.h.15.attn.c_proj\n",
            "  - transformer.h.15.mlp.c_fc\n",
            "  - transformer.h.15.mlp.c_proj\n",
            "  - transformer.h.16.attn.c_attn\n",
            "  - transformer.h.16.attn.c_proj\n",
            "  - transformer.h.16.mlp.c_fc\n",
            "  - transformer.h.16.mlp.c_proj\n",
            "  - transformer.h.17.attn.c_attn\n",
            "  - transformer.h.17.attn.c_proj\n",
            "  - transformer.h.17.mlp.c_fc\n",
            "  - transformer.h.17.mlp.c_proj\n",
            "  - transformer.h.18.attn.c_attn\n",
            "  - transformer.h.18.attn.c_proj\n",
            "  - transformer.h.18.mlp.c_fc\n",
            "  - transformer.h.18.mlp.c_proj\n",
            "  - transformer.h.19.attn.c_attn\n",
            "  - transformer.h.19.attn.c_proj\n",
            "  - transformer.h.19.mlp.c_fc\n",
            "  - transformer.h.19.mlp.c_proj\n",
            "  - transformer.h.20.attn.c_attn\n",
            "  - transformer.h.20.attn.c_proj\n",
            "  - transformer.h.20.mlp.c_fc\n",
            "  - transformer.h.20.mlp.c_proj\n",
            "  - transformer.h.21.attn.c_attn\n",
            "  - transformer.h.21.attn.c_proj\n",
            "  - transformer.h.21.mlp.c_fc\n",
            "  - transformer.h.21.mlp.c_proj\n",
            "  - transformer.h.22.attn.c_attn\n",
            "  - transformer.h.22.attn.c_proj\n",
            "  - transformer.h.22.mlp.c_fc\n",
            "  - transformer.h.22.mlp.c_proj\n",
            "  - transformer.h.23.attn.c_attn\n",
            "  - transformer.h.23.attn.c_proj\n",
            "  - transformer.h.23.mlp.c_fc\n",
            "  - transformer.h.23.mlp.c_proj\n",
            "  - transformer.h.24.attn.c_attn\n",
            "  - transformer.h.24.attn.c_proj\n",
            "  - transformer.h.24.mlp.c_fc\n",
            "  - transformer.h.24.mlp.c_proj\n",
            "  - transformer.h.25.attn.c_attn\n",
            "  - transformer.h.25.attn.c_proj\n",
            "  - transformer.h.25.mlp.c_fc\n",
            "  - transformer.h.25.mlp.c_proj\n",
            "  - transformer.h.26.attn.c_attn\n",
            "  - transformer.h.26.attn.c_proj\n",
            "  - transformer.h.26.mlp.c_fc\n",
            "  - transformer.h.26.mlp.c_proj\n",
            "  - transformer.h.27.attn.c_attn\n",
            "  - transformer.h.27.attn.c_proj\n",
            "  - transformer.h.27.mlp.c_fc\n",
            "  - transformer.h.27.mlp.c_proj\n",
            "  - transformer.h.28.attn.c_attn\n",
            "  - transformer.h.28.attn.c_proj\n",
            "  - transformer.h.28.mlp.c_fc\n",
            "  - transformer.h.28.mlp.c_proj\n",
            "  - transformer.h.29.attn.c_attn\n",
            "  - transformer.h.29.attn.c_proj\n",
            "  - transformer.h.29.mlp.c_fc\n",
            "  - transformer.h.29.mlp.c_proj\n",
            "  - transformer.h.30.attn.c_attn\n",
            "  - transformer.h.30.attn.c_proj\n",
            "  - transformer.h.30.mlp.c_fc\n",
            "  - transformer.h.30.mlp.c_proj\n",
            "  - transformer.h.31.attn.c_attn\n",
            "  - transformer.h.31.attn.c_proj\n",
            "  - transformer.h.31.mlp.c_fc\n",
            "  - transformer.h.31.mlp.c_proj\n",
            "  - lm_head\n",
            "\n",
            "Modules containing common patterns:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=trainable_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "AQQvJEnBu1Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUHht8tPvhWO",
        "outputId": "a4be6a01-5d90-4a3a-8f9f-d72ff6e2d8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:543: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Trainable parameters:\")\n",
        "trainable_params = 0\n",
        "all_params = 0\n",
        "for name, param in model.named_parameters():\n",
        "    all_params += param.numel()\n",
        "    if param.requires_grad:\n",
        "        trainable_params += param.numel()\n",
        "        print(f\"{name}: {param.shape}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,} ({100 * trainable_params / all_params:.2f}% of {all_params:,})\")"
      ],
      "metadata": {
        "id": "GDYGyygd12Vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a1395d-619b-4ab2-f701-6f93026a98cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters:\n",
            "base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.0.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.0.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.1.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.1.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.2.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.2.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.3.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.3.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.4.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.4.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.5.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.5.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.6.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.6.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.7.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.7.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.8.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.8.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.9.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.9.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.10.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.10.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.11.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.11.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.12.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.12.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.12.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.12.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.12.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.12.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.12.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.12.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.13.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.13.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.13.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.13.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.13.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.13.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.13.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.13.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.14.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.14.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.14.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.14.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.14.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.14.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.14.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.14.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.15.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.15.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.15.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.15.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.15.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.15.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.15.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.15.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.16.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.16.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.16.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.16.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.16.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.16.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.16.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.16.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.17.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.17.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.17.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.17.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.17.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.17.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.17.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.17.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.18.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.18.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.18.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.18.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.18.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.18.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.18.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.18.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.19.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.19.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.19.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.19.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.19.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.19.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.19.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.19.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.20.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.20.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.20.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.20.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.20.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.20.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.20.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.20.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.21.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.21.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.21.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.21.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.21.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.21.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.21.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.21.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.22.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.22.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.22.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.22.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.22.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.22.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.22.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.22.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.23.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.23.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.23.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.23.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.23.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.23.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.23.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.23.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.24.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.24.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.24.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.24.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.24.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.24.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.24.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.24.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.25.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.25.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.25.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.25.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.25.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.25.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.25.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.25.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.26.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.26.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.26.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.26.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.26.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.26.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.26.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.26.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.27.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.27.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.27.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.27.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.27.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.27.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.27.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.27.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.28.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.28.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.28.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.28.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.28.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.28.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.28.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.28.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.29.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.29.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.29.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.29.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.29.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.29.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.29.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.29.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.30.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.30.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.30.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.30.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.30.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.30.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.30.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.30.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.31.attn.c_attn.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.31.attn.c_attn.lora_B.default.weight: torch.Size([7680, 16])\n",
            "base_model.model.transformer.h.31.attn.c_proj.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.31.attn.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.transformer.h.31.mlp.c_fc.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.transformer.h.31.mlp.c_fc.lora_B.default.weight: torch.Size([10240, 16])\n",
            "base_model.model.transformer.h.31.mlp.c_proj.lora_A.default.weight: torch.Size([16, 10240])\n",
            "base_model.model.transformer.h.31.mlp.c_proj.lora_B.default.weight: torch.Size([2560, 16])\n",
            "base_model.model.lm_head.lora_A.default.weight: torch.Size([16, 2560])\n",
            "base_model.model.lm_head.lora_B.default.weight: torch.Size([28896, 16])\n",
            "Trainable parameters: 21,474,816 (1.58% of 1,357,431,296)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    fp16=True,\n",
        "    torch_compile=False,\n",
        "    dataloader_num_workers=0,\n",
        "    optim=\"adamw_8bit\",\n",
        ")"
      ],
      "metadata": {
        "id": "uPu6a7DN2C90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83cb27d-7c04-49f5-b9e3-47daad1f75b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"validation\" not in dataset:\n",
        "    train_valid_split = tokenized_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "    train_dataset = train_valid_split[\"train\"]\n",
        "    eval_dataset = train_valid_split[\"test\"]\n",
        "else:\n",
        "    train_dataset = tokenized_dataset[\"train\"]\n",
        "    eval_dataset = tokenized_dataset[\"validation\"]"
      ],
      "metadata": {
        "id": "22fFogwN2Czq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.select(range(min(1000, len(train_dataset))))\n",
        "eval_dataset = eval_dataset.select(range(min(100, len(eval_dataset))))"
      ],
      "metadata": {
        "id": "V0DZmK7hIZ6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")"
      ],
      "metadata": {
        "id": "cWWmLSGj2QfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Y2rWOqB-2QCb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "d0c4dc24-148a-4f5a-a9fc-578115be8129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msanaimran6722\u001b[0m (\u001b[33msanaimran6722-octaloop-technologies\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250313_061752-3fu2z1dt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sanaimran6722-octaloop-technologies/huggingface/runs/3fu2z1dt' target=\"_blank\">./medical-o1-reasoning-SFT</a></strong> to <a href='https://wandb.ai/sanaimran6722-octaloop-technologies/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sanaimran6722-octaloop-technologies/huggingface' target=\"_blank\">https://wandb.ai/sanaimran6722-octaloop-technologies/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sanaimran6722-octaloop-technologies/huggingface/runs/3fu2z1dt' target=\"_blank\">https://wandb.ai/sanaimran6722-octaloop-technologies/huggingface/runs/3fu2z1dt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [186/186 39:42, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=186, training_loss=3.0839216991137435, metrics={'train_runtime': 2481.1947, 'train_samples_per_second': 1.209, 'train_steps_per_second': 0.075, 'total_flos': 1.154429459890176e+16, 'train_loss': 3.0839216991137435, 'epoch': 2.96})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(output_dir + \"/final_model\")\n",
        "model.save_pretrained(output_dir + \"/peft_adapter\")\n",
        "tokenizer.save_pretrained(output_dir + \"/peft_adapter\")"
      ],
      "metadata": {
        "id": "iXy9wWNA2P18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce10b39-3e19-42fc-d8f8-f070ef745aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./medical-o1-reasoning-SFT/peft_adapter/tokenizer_config.json',\n",
              " './medical-o1-reasoning-SFT/peft_adapter/special_tokens_map.json',\n",
              " './medical-o1-reasoning-SFT/peft_adapter/vocab.json',\n",
              " './medical-o1-reasoning-SFT/peft_adapter/merges.txt',\n",
              " './medical-o1-reasoning-SFT/peft_adapter/added_tokens.json',\n",
              " './medical-o1-reasoning-SFT/peft_adapter/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_medical_response(question, max_length=512):\n",
        "    prompt = f\"Question: {question}\\n\\nProvide a comprehensive medical answer with potential complications:\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_length=max_length,\n",
        "            temperature=0.3,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            repetition_penalty=1.2,\n",
        "            no_repeat_ngram_size=3,\n",
        "            num_return_sequences=1,\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = response.replace(prompt, \"\").strip()\n",
        "    return response"
      ],
      "metadata": {
        "id": "sVHhCf482xdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_question = \"What are the potential complications of untreated hypertension?\"\n",
        "generated_response = generate_medical_response(test_question)\n",
        "print(f\"Question: {test_question}\")\n",
        "print(f\"Generated response: {generated_response}\")"
      ],
      "metadata": {
        "id": "SWRPwz1e3M6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dcde27e-3010-43dd-c5ef-3c81b396e77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:28895 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test_set(test_dataset, num_samples=10):\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    for i in range(min(num_samples, len(test_dataset))):\n",
        "        sample = test_dataset[i]\n",
        "        question = sample[\"Question\"]\n",
        "        actual_response = sample[\"Response\"]\n",
        "\n",
        "        generated = generate_medical_response(question)\n",
        "\n",
        "        results.append({\n",
        "            \"question\": question,\n",
        "            \"actual\": actual_response,\n",
        "            \"generated\": generated\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "2InDbR6W3SK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"test\" in dataset:\n",
        "    test_results = evaluate_on_test_set(dataset[\"test\"])\n",
        "    for i, result in enumerate(test_results):\n",
        "        print(f\"Example {i+1}:\")\n",
        "        print(f\"Question: {result['question']}\")\n",
        "        print(f\"Actual: {result['actual']}\")\n",
        "        print(f\"Generated: {result['generated']}\")\n",
        "        print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "W-87_Rvb3SG-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}